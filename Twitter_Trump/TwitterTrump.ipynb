{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Gunnar\\Anaconda3\\envs\\dml2\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Libraries to be used\n",
    "\n",
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Embedding, LSTM, Bidirectional\n",
    "from keras.layers import Dense, TimeDistributed, Activation, Dropout\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "# Callbacks for training\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Gensim models\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import stem\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "# Misc imports #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Read csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (29246, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Wow so many Fake News stories today. No matter...</td>\n",
       "      <td>10-04-2017 11:29:43</td>\n",
       "      <td>9898.0</td>\n",
       "      <td>37312</td>\n",
       "      <td>false</td>\n",
       "      <td>9.155394e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>A great day in Puerto Rico yesterday. While so...</td>\n",
       "      <td>10-04-2017 10:25:58</td>\n",
       "      <td>5493.0</td>\n",
       "      <td>28436</td>\n",
       "      <td>false</td>\n",
       "      <td>9.155234e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>My Administration will continue to work around...</td>\n",
       "      <td>10-04-2017 00:53:10</td>\n",
       "      <td>9208.0</td>\n",
       "      <td>41079</td>\n",
       "      <td>false</td>\n",
       "      <td>9.153792e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @PressSec: .@POTUS and @FLOTUS meet w/ some...</td>\n",
       "      <td>10-04-2017 00:28:24</td>\n",
       "      <td>5631.0</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>9.153730e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @seanhannity: Tonight the truth about how d...</td>\n",
       "      <td>10-04-2017 00:27:11</td>\n",
       "      <td>7427.0</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>9.153727e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  Wow so many Fake News stories today. No matter...   \n",
       "1  Twitter for iPhone  A great day in Puerto Rico yesterday. While so...   \n",
       "2  Twitter for iPhone  My Administration will continue to work around...   \n",
       "3  Twitter for iPhone  RT @PressSec: .@POTUS and @FLOTUS meet w/ some...   \n",
       "4  Twitter for iPhone  RT @seanhannity: Tonight the truth about how d...   \n",
       "\n",
       "            created_at  retweet_count favorite_count is_retweet        id_str  \n",
       "0  10-04-2017 11:29:43         9898.0          37312      false  9.155394e+17  \n",
       "1  10-04-2017 10:25:58         5493.0          28436      false  9.155234e+17  \n",
       "2  10-04-2017 00:53:10         9208.0          41079      false  9.153792e+17  \n",
       "3  10-04-2017 00:28:24         5631.0              0       true  9.153730e+17  \n",
       "4  10-04-2017 00:27:11         7427.0              0       true  9.153727e+17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data = pd.read_csv('TrumpTweets.csv')\n",
    "print(\"Shape of dataset: \"+str(twitter_data.shape))\n",
    "twitter_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_cleanup(text):\n",
    "    # Define allowed characters in text\n",
    "    cap = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    low = cap.lower()\n",
    "    spc = '.,#@/!?: '\n",
    "    nbr = '0123456789'\n",
    "    allowed_chars = cap + low + spc + nbr\n",
    "    \n",
    "    # Iterate though text and keep only allowed characters\n",
    "    new = \"\"\n",
    "    for character in text:\n",
    "        print(character)\n",
    "        if character in allowed_chars:\n",
    "            new += character\n",
    "        else:\n",
    "            new += \" \"\n",
    "    # Remove consecutive spaces\n",
    "    new = re.sub(\" +\",\" \" ,new)\n",
    "    # Remove space at end of list\n",
    "    if new[-1]==\" \":\n",
    "        new = new[0:-1]\n",
    "    return new\n",
    "\n",
    "# Formatting text\n",
    "def text_format(text):\n",
    "    text = add_space_after(text,\"!\")\n",
    "    text = add_space_before(text,\"#\")\n",
    "    text = add_space_before(text,\"@\")\n",
    "    text = add_space_after(text,\",\");\n",
    "    # Remove consecutive spaces\n",
    "    text = re.sub(\" +\",\" \" ,text)\n",
    "    # Remove space at end of list\n",
    "    if text[-1]==\" \":\n",
    "        text = text[0:-1]\n",
    "    return text\n",
    "\n",
    "# Add space after selected sign in text\n",
    "def add_space_after(text,sign):\n",
    "    text = text.replace(sign,sign + \" \")\n",
    "    return text\n",
    "\n",
    "# Add space before selected sign in text\n",
    "def add_space_before(text,sign):\n",
    "    text = text.replace(sign,\" \"+ sign)\n",
    "    return text\n",
    "\n",
    "def add_spaces_around(text):\n",
    "    space = '.,!?' \n",
    "    for i in space:\n",
    "        text = text.replace(i,\" \" + i + \" \")\n",
    "    # Remove consecutive spaces\n",
    "    text = re.sub(\" +\",\" \" ,text)\n",
    "    # Remove space at end of list\n",
    "    if text[-1]==\" \":\n",
    "        text = text[0:-1]   \n",
    "    return text\n",
    "        \n",
    "# Extract and replace hashtags in list\n",
    "def remove_hashtags(text):\n",
    "    # Set hashtag holder\n",
    "    hashtagholder = \"#TAG\"\n",
    "    # Declare variable\n",
    "    hashtags = [];\n",
    "    text_out = \"\";\n",
    "    # Split text by spaces\n",
    "    text_vec = text.split(\" \")\n",
    "    \n",
    "    # For all words in the text vector\n",
    "    for word in text_vec:\n",
    "        # If there exist an hashtag\n",
    "        if word.find(\"#\")>-1:\n",
    "            # Append hashtag\n",
    "            hashtags.append(word)\n",
    "            \n",
    "            # Replace hashtag with hashtagholder in text\n",
    "            if len(text_out)<1:\n",
    "                text_out = hashtagholder\n",
    "            else:\n",
    "                text_out = text_out + \" \" + hashtagholder\n",
    "        else:\n",
    "            # Add the word to the text vector\n",
    "            if len(text_out)<1:\n",
    "                text_out = word\n",
    "            else:\n",
    "                text_out = text_out + \" \" + word\n",
    "                \n",
    "    # Return hashtags and modified text\n",
    "    return hashtags,text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_ats(text):\n",
    "    # Set @ holder\n",
    "    atholder = \"@PERSON\"\n",
    "    # Initiate variables\n",
    "    ats = [];\n",
    "    text_out = \"\";\n",
    "    # Split text on spaces\n",
    "    text_vec = text.split(\" \")\n",
    "    # For each word in text\n",
    "    for word in text_vec:\n",
    "        # If an @ exist\n",
    "        if word.find(\"@\")>-1:\n",
    "            # Append @\n",
    "            ats.append(word)\n",
    "            # Replace at with atholder\n",
    "            if len(text_out)<1:\n",
    "                text_out = atholder\n",
    "            else:\n",
    "                text_out = text_out + \" \" + atholder\n",
    "                \n",
    "        # Else add the word to the output vector\n",
    "        else:\n",
    "            if len(text_out)<1:\n",
    "                text_out = word\n",
    "            else:\n",
    "                text_out = text_out + \" \" + word\n",
    "    # Return ats and text        \n",
    "    return ats,text_out\n",
    "\n",
    "def remove_links(text):\n",
    "    # Define link holder\n",
    "    linkholder = 'HTTPSLINK'\n",
    "    # Initiate variables\n",
    "    links = [];\n",
    "    text_out = \"\";\n",
    "    \n",
    "    \n",
    "    # Find index where http starts\n",
    "    st = text.find('http')\n",
    "    # Find https\n",
    "    if text.find('http')>-1:\n",
    "\n",
    "        \n",
    "        # Extract link part from the remaining text\n",
    "        link_part = text[st:]\n",
    "        \n",
    "        # Split link part on spaces\n",
    "        lnk = link_part.split(\" \")\n",
    "        \n",
    "        # For all links in linklist\n",
    "        for link in lnk:\n",
    "            # If link is true link, else the link is ignored\n",
    "            if link.find(\"http\")>-1:\n",
    "                links.append(link)\n",
    "        text_out = text[:st-1] + (\" \" + linkholder)*len(links)\n",
    "    else:\n",
    "        text_out = text\n",
    "    # Add text and linkholders to text\n",
    "    \n",
    "    return links,text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sentences(raw_text):\n",
    "    #Input: list of texts(tweets)\n",
    "    #Output: list of sentences\n",
    "    length=len(raw_text)\n",
    "    sentences=[]\n",
    "    #every line in raw text\n",
    "    for tweet in range(len(raw_text)):\n",
    "        #split into sentences\n",
    "        try:\n",
    "            tweet_split=raw_text[tweet].split('.')\n",
    "        except:\n",
    "            print('Failed on:' ,raw_text[tweet],'index:',tweet)\n",
    "        #append all sentences\n",
    "        for sentence in tweet_split:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "def to_word_list(filtered_sentences):\n",
    "    #Input: list of sentences\n",
    "    #Output: list of unique words\n",
    "    vocab=[]\n",
    "    for sentence in filtered_sentences:\n",
    "        sentence=sentence.lower()\n",
    "        sentence=sentence.split(' ') \n",
    "        for word in sentence:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "RT @PERSON Under POTUS @PERSON ??S amp P 500 38th?Record High ??NASDAQ 44th?Record High?? #TAG HTTPSLINK\n",
      "RT @PERSON Under POTUS @PERSON ??S amp P 500 38th?Record High ??NASDAQ 44th?Record High?? #TAG HTTPSLINK\n",
      "RT @PERSON Under POTUS @PERSON ? ? S amp P 500 38th ? Record High ? ? NASDAQ 44th ? Record High ? ? #TAG HTTPSLINK\n",
      "RT @PERSON Under POTUS @PERSON ? ? S amp P 500 38th ? Record High ? ? NASDAQ 44th ? Record High ? ? #TAG HTTPSLINK\n",
      "RT @PERSON Under POTUS @PERSON ? ? S amp P 500 38th ? Record High ? ? NASDAQ 44th ? Record High ? ? #TAG HTTPSLINK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "line = 'RT @DonnaWR8: @realDonaldTrump I        wonder what this BRAVE American would give to stand on his OWN two legs just ONCE MORE for our #Anthem?â€¦'\n",
    "line = 'RT @DonnaWR8: .@POTUS #TRUMPðŸ‡ºðŸ‡¸ &amp; I @FLOTUSðŸŒºWhen ALL seemed HOPELESS...YOU brought HOPE!You INSPIRE us ALL!#MAGA #Harvey @Scavino45 #USAâ€¦'\n",
    "#line = 'Hillarys Two Official Favors To Morocco Resulted In $28 Million For Clinton Foundation #DrainTheSwamphttps://t.co/6qOO7FZSvF'\n",
    "#line = 'RT @TwitterData: These are the 10 most Tweeted about world leaders during the first day of #UNGA General Debate https://t.co/HhlOlNAkDJ'\n",
    "line = '@davidsidol: Great meeting @realDonaldTrump today!. #TrumpGolf #TrumpNationalCharlotte #1stclass http://t.co/KDKPgyANGV'\n",
    "\n",
    "line = 'It is time to rebuild OUR country to bring back OUR jobs to restore OUR dreams &amp; yes to put #AmericaFirst! TY Oâ€¦ https://t.co/2b2bXwxGkA'\n",
    "line = 'RT @PERSON Under POTUS @PERSON ??S&amp;P 500 38th?Record High ??NASDAQ 44th?Record High?? #TAG HTTPSLINK'\n",
    "print(type(line))\n",
    "line = text_cleanup(line)\n",
    "print(line)\n",
    "line = text_format(line);\n",
    "print(line)\n",
    "x,line = remove_links(line)\n",
    "line = add_spaces_around(line)\n",
    "print(line)\n",
    "hashtags, line = remove_hashtags(line)\n",
    "print(line)\n",
    "ats, line = remove_ats(line)\n",
    "print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sentences(raw_text):\n",
    "    #Input: list of texts(tweets)\n",
    "    #Output: list of sentences\n",
    "    length=len(raw_text)\n",
    "    sentences=[]\n",
    "    #every line in raw text\n",
    "    for tweet in range(len(raw_text)):\n",
    "        #split into sentences\n",
    "        try:\n",
    "            tweet_split=raw_text[tweet].split('.')\n",
    "        except:\n",
    "            print('Failed on:' ,raw_text[tweet],'index:',tweet)\n",
    "        #append all sentences\n",
    "        for sentence in tweet_split:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "def to_word_list(filtered_sentences):\n",
    "    #Input: list of sentences\n",
    "    #Output: list of unique words\n",
    "    vocab=[]\n",
    "    for sentence in filtered_sentences:\n",
    "        sentence=sentence.lower()\n",
    "        sentence=sentence.split(' ') \n",
    "        for word in sentence:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "#print(twitter_data)\n",
    "\n",
    "tweets = twitter_data['text'].values\n",
    "print(type(tweets))\n",
    "\n",
    "filter_ats = [];\n",
    "filter_hashtags =[];\n",
    "filter_links = [];\n",
    "filter_tweets = [];\n",
    "error_index = []\n",
    "for i in range(len(tweets)):\n",
    "    \n",
    "    #if i == 292:\n",
    "        #print(i)\n",
    "        tweet = tweets[i]\n",
    "        #print(tweet)\n",
    "        if type(tweet) == str:\n",
    "            #print(type(tweet))\n",
    "            #print(tweet)\n",
    "            tweet_out = text_cleanup(tweet)\n",
    "            tweet_out = text_format(tweet)\n",
    "            #print(tweet_out)\n",
    "            links, tweet_out = remove_links(tweet_out)\n",
    "            tweet_out = add_spaces_around(tweet_out)\n",
    "            #print(tweet_out)\n",
    "            hashtags, tweet_out = remove_hashtags(tweet_out)\n",
    "            #print(tweet_out)\n",
    "            ats, tweet_out = remove_ats(tweet_out)\n",
    "            filter_tweets.append(tweet_out)\n",
    "            filter_ats.append(ats)\n",
    "            filter_hashtags.append(hashtags)\n",
    "            filter_links.append(links)\n",
    "        else:\n",
    "            filter_tweets.append('')\n",
    "            filter_ats.append([])\n",
    "            filter_hashtags.append([])\n",
    "            filter_links.append([])\n",
    "            error_index.append(i)\n",
    "print(filter_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29246\n",
      "[ 'Wow so many Fake News stories today. No matter what I do or say they will not write or speak truth. The Fake News Media is out of control!'\n",
      " 'A great day in Puerto Rico yesterday. While some of the news coverage is Fake most showed great warmth and friendship.'\n",
      " 'My Administration will continue to work around the clock with Governor @RicardoRossello &amp; his team. Great progress being made! #PRStrong🇵🇷 https://t.co/1aL9YrwTvC'\n",
      " ...,\n",
      " 'Donald Trump reads Top Ten Financial Tips on Late Show with David Letterman: http://tinyurl.com/ooafwn - Very funny!'\n",
      " 'Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion!'\n",
      " 'Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight!'] 29246\n",
      "[28872]\n"
     ]
    }
   ],
   "source": [
    "# Cerate dataframe with id and labels\n",
    "print(len(filter_tweets))\n",
    "print((tweets),len(filter_tweets))\n",
    "print(error_index)\n",
    "d = {'Original_tweet': tweets, 'filtered_tweet' : filter_tweets}\n",
    "df = pd.DataFrame(d)\n",
    "# Save to csv file\n",
    "df.to_csv('out.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " ['#PRStrong🇵🇷'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USVI'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TeamUSA🇺🇸🏆on'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#NationalAnthem'],\n",
       " ['#StandForOurAnthem🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " ['#FakeNews'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#FakeNews', '#PRStrong🇵🇷'],\n",
       " [],\n",
       " ['#FakeNews', '#PRStrong🇵🇷'],\n",
       " [],\n",
       " ['#FEMA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#DoD', '#PuertoRico', '#USVI'],\n",
       " ['#AirForce', '#PuertoRico', '#VirginIslands'],\n",
       " ['#police', '#fire', '#government'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USNSComfort', '#PuertoRico'],\n",
       " ['#MakeAmericaGreatAgain🇺🇸'],\n",
       " ['#TaxReform'],\n",
       " ['#PuertoRico'],\n",
       " [],\n",
       " ['#Hannityat9'],\n",
       " ['#AmericaFirst-', '#Dobbs', '#MAGA…'],\n",
       " ['#LESM'],\n",
       " ['#WeeklyAddress🇺'],\n",
       " [],\n",
       " ['#TaxReform'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#PuertoRico', '#HurricaneMaria'],\n",
       " [],\n",
       " [],\n",
       " ['#TeamScalise'],\n",
       " [],\n",
       " [],\n",
       " ['#TaxReform', '#USA🇺🇸'],\n",
       " ['#TaxReform'],\n",
       " ['#TaxReform'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USA🇺🇸'],\n",
       " ['#NoKo'],\n",
       " [],\n",
       " ['#PuertoRico', '#USVI'],\n",
       " ['#USA🇺🇸'],\n",
       " ['#SituationRoom'],\n",
       " ['#USA🇺🇸'],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#FEMA'],\n",
       " [],\n",
       " [],\n",
       " ['#StandForOurAnthem🇺🇸'],\n",
       " [],\n",
       " ['#FakeNews'],\n",
       " ['#StandForOurAnt…'],\n",
       " ['#StandForOurAnthem'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Anthem'],\n",
       " ['#NFL', '#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USAatUNGA🇺🇸', '#UNGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TRUMP🇺🇸', '#MAGA', '#Harvey', '#USA…'],\n",
       " ['#UNGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#NoKo'],\n",
       " ['#UNGA'],\n",
       " ['#UNGA'],\n",
       " ['#USAatUNGA', '#UNGA'],\n",
       " ['#PRStrong'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#WeThePeople🇺🇸', '#USAatUNGA', '#UNGA'],\n",
       " ['#USA…'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USAatUNGA🇺🇸', '#UNG'],\n",
       " [],\n",
       " ['#AmericaFirst🇺🇸', '#UNGAFull'],\n",
       " ['#NoKo'],\n",
       " [],\n",
       " [],\n",
       " ['#USAatUNGA🇺🇸', '#UNGA'],\n",
       " [],\n",
       " ['#UNGA'],\n",
       " ['#UNGA'],\n",
       " [],\n",
       " ['#USAatUNGA', '#UNGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " ['#CrookedHillary'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#NYTimes'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#FAKE'],\n",
       " ['#Irma', '#Dobbs', '#MA…'],\n",
       " ['#NeverForget911'],\n",
       " ['#NeverForget'],\n",
       " [],\n",
       " [\"#Irma's\"],\n",
       " ['#HurricaneIrma', '#HurricaneJose'],\n",
       " [],\n",
       " ['#HurricaneIrma'],\n",
       " [],\n",
       " ['#harvey', '#irma'],\n",
       " ['#HurricaineIrma'],\n",
       " ['#Florida'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#IrmaHurricane2017'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#OneAmericaAppeal'],\n",
       " ['#HurricaneIrma'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#FEMA'],\n",
       " ['#USA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#LaborDay'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#LEOs', '#CajunNavy'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TexasStrong'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#SouthernBaptist'],\n",
       " [],\n",
       " [],\n",
       " ['#HurricaneHarvey', '#PrayForTexas'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TexasStrong'],\n",
       " [],\n",
       " ['#Veterans', '#HurricaneHarvey'],\n",
       " [],\n",
       " ['#TaxRefo…'],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#thefive'],\n",
       " ['#PhotosFromTheField:', '#Harvey', '#TMDHarvey'],\n",
       " [],\n",
       " ['#HurricaneHarvey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Harvey'],\n",
       " [],\n",
       " [],\n",
       " ['#Harvey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#HurricaneHarvey'],\n",
       " ['#HurricaneHarvey'],\n",
       " ['#Harvey'],\n",
       " [],\n",
       " ['#Harvey'],\n",
       " [],\n",
       " ['#Harvey'],\n",
       " ['#HurricaneHarvey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#HurricaneHarvey'],\n",
       " ['#HurricaneHarvey'],\n",
       " ['#HurricaneHarvey'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " ['#HurricaneHarvey'],\n",
       " [],\n",
       " [],\n",
       " ['#HurricaneHarvey', '#PlanAhead'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#ALConv2017'],\n",
       " [],\n",
       " ['#ALConv2017'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#DrainTheSwamp', '#PhoenixRally'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA🇺🇸Tickets:'],\n",
       " ['#USSJohnSMcCain'],\n",
       " [],\n",
       " [],\n",
       " ['#USA🇺🇸'],\n",
       " ['#AfghanStrategy'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USSJohnSMcCain'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#LESM'],\n",
       " ['#HR873'],\n",
       " ['#MAGA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " ['#NeverTrumpers'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TrumpTrain‼️'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Fake'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"#Virginia's\", '#Charlot…'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Charlottesville'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USAF', '#bombers', '#FightTonight'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#GES2017'],\n",
       " [],\n",
       " [],\n",
       " ['#ObamaDay'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#GodBlessTheUSA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#thefive'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#PurpleHeartDay💜I', '#USA🇺🇸'],\n",
       " ['#PurpleHeartDay💜I', '#USA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Fake'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#ISIS'],\n",
       " ['#AmericaFirst🇺🇸'],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " ['#CG227🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " ['#BreakingNews:', '#JobsReport'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA🇺🇸'],\n",
       " ['#VAVideoConnect'],\n",
       " ['#USA'],\n",
       " ['#MakeAmericaGreatAgain🇺🇸Tickets:'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Fake'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MS13', '#MS13', '#LESM'],\n",
       " ['#LESMHarrisburg', '#FlashbackFriday', '#MS13'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TeamScalise'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MakeAmericaGreatAgain🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#2017Jambo-'],\n",
       " ['#OCareNightmare'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USSGeraldRFord:☑️Keep'],\n",
       " ['#USSGeraldRFord', '#USA'],\n",
       " ['#USSGeraldRFord'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USSArizona', '#HonorThem🇺🇸Remarks:'],\n",
       " ['#USSArizona'],\n",
       " [],\n",
       " ['#MadeInAmerica'],\n",
       " [],\n",
       " ['#MadeInAmerica🇺🇸'],\n",
       " [],\n",
       " ['#AmericaFirst🇺🇸'],\n",
       " ['#MAGA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USWomensOpen🇺🇸'],\n",
       " ['#USWomensOpen'],\n",
       " ['#USSJohnFinn'],\n",
       " [],\n",
       " ['#Fake'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USWomensOpen🇺🇸'],\n",
       " ['#USWomensOpen'],\n",
       " [],\n",
       " ['#WeeklyAddress🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#USWomensOpen'],\n",
       " [],\n",
       " ['#BastilleDay', '#14juillet'],\n",
       " [],\n",
       " ['#USWomensOpen'],\n",
       " [],\n",
       " [],\n",
       " ['#BastilleDay'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA🇺🇸'],\n",
       " ['#MAGA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TheFive'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#RealPresident', '#Obama', '#Democrat'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#G20Summit'],\n",
       " ['#G20Summit'],\n",
       " ['#FakeNews'],\n",
       " ['#G20Summit', '#USA'],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " ['#G20Summit', '#USA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#POTUSinPoland'],\n",
       " ['#ICYMI'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#HappyIndependenceDay', '#USA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " ['#HappyIndependenceDay', '#July4', '#USA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " ['#MSM'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#CharlieGard'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#FraudNewsCNN', '#FNN'],\n",
       " [],\n",
       " [],\n",
       " ['#FakeNews', '#FraudNewsCNN'],\n",
       " ['#FakeNews'],\n",
       " [],\n",
       " [],\n",
       " ['#KatesLaw', '#NoSanctuaryForCriminalsActStatement:'],\n",
       " [],\n",
       " ['#FakeNews'],\n",
       " [],\n",
       " [],\n",
       " ['#Canada150'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#KatesLaw'],\n",
       " [],\n",
       " ['#UnleashingAmericanEnerg'],\n",
       " ['#NoSanctuaryForCriminalsAct', '#KatesLaw', '#SaveAmericanLives'],\n",
       " ['#NoSanctuaryForCriminalsAct', '#KatesLaw'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#KatesLaw'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#ICYMI-'],\n",
       " ['#AmazonWashingtonPost'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Obamacare'],\n",
       " [],\n",
       " [],\n",
       " ['#Obamacare'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#VAaccountability'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#TeamScalise'],\n",
       " ['#AmericaFirst🇺🇸'],\n",
       " ['#HealthcareBill'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#VoteKarenHandel'],\n",
       " ['#GA06'],\n",
       " ['#VoteKarenHandel'],\n",
       " ['#GA06'],\n",
       " ['#VoteRalphNorman'],\n",
       " [],\n",
       " ['#USSFitzgerald'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"#'s\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Hannity'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#CongressionalBaseballGame⚾️'],\n",
       " ['#WorkforceWeek'],\n",
       " [],\n",
       " [],\n",
       " ['#MAGA'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#OttoWarmbier'],\n",
       " [],\n",
       " ['#MAGA🇺🇸'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#PulseNightClub'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['#Obamacare'],\n",
       " [],\n",
       " [],\n",
       " ['#FakeNews', '#DOW', '#NASDAQ'],\n",
       " ['#AmericaFirst', '#InfrastructureWeek…'],\n",
       " [],\n",
       " ['#AmericaFirst'],\n",
       " [],\n",
       " ...]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = twitter_data.keys()\n",
    "print(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(sentence):\n",
    "    sent = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        a = word.find('http')\n",
    "        if a:\n",
    "            sent.append(word)  \n",
    "    lst = ' '.join(sent)\n",
    "    return lst\n",
    "\n",
    "tweets = twitter_data['text'].values\n",
    "\n",
    "print(tweets[2])\n",
    "sent = remove_links(tweets[2])\n",
    "print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = twitter_data['text'].values\n",
    "sentences = [];\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    tweet = tweets[i]\n",
    "    \n",
    "    try:\n",
    "        tweet = remove_links(tweet)\n",
    "        idx = tweet.find(\".\")\n",
    "    except:\n",
    "        print(i)\n",
    "        continue\n",
    "    a = tweet.split(\".\")\n",
    "    sentences.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentences))\n",
    "sentences[10]\n",
    "print(len(str_list))\n",
    "sentences[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
